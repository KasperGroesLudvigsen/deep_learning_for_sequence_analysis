{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b65974-b641-49a9-80dc-45bcd47d588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcc778f-eb16-4531-8832-2adc29f42aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting sentences from raw data in korpus 1990\n"
     ]
    }
   ],
   "source": [
    "_, sentences, _ = preprocessing.extract_sentences_from_raw_txt(skip_no_comma=False, korpus=\"1990\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc56a0f-6d8c-42a4-8c74-18e68448a072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stå',\n",
       " 'JuniBevægelsen',\n",
       " 'for',\n",
       " 'en',\n",
       " 'alternativ',\n",
       " 'inden',\n",
       " 'for',\n",
       " 'EF',\n",
       " 'medlemskab',\n",
       " ',',\n",
       " 'eller',\n",
       " 'være',\n",
       " 'realitet',\n",
       " 'ikke',\n",
       " ',',\n",
       " 'at',\n",
       " 'JuniBevægelsens',\n",
       " 'lede',\n",
       " 'kraft',\n",
       " 'ønske',\n",
       " 'Danmark',\n",
       " 'ud',\n",
       " 'af',\n",
       " 'EF',\n",
       " ',',\n",
       " 'men',\n",
       " 'undlade',\n",
       " 'at',\n",
       " 'sige',\n",
       " 'det',\n",
       " 'af',\n",
       " 'taktisk',\n",
       " 'grund',\n",
       " 'minut',\n",
       " 'dessert',\n",
       " 'smelte',\n",
       " 'på',\n",
       " 'tunge',\n",
       " ',',\n",
       " 'men',\n",
       " 'den',\n",
       " 'stor',\n",
       " 'stykke',\n",
       " 'valnøddefragilité',\n",
       " ',',\n",
       " 'anrette',\n",
       " 'i',\n",
       " 'en',\n",
       " 'abrikoscouli',\n",
       " ',',\n",
       " 'der',\n",
       " 'overdøve',\n",
       " 'smag',\n",
       " 'af',\n",
       " 'kirsch',\n",
       " ',',\n",
       " 'være',\n",
       " 'en',\n",
       " 'kaloriebombe',\n",
       " 'så',\n",
       " 'stor',\n",
       " 'og',\n",
       " 'mætte',\n",
       " ',',\n",
       " 'at',\n",
       " 'jeg',\n",
       " 'måtte',\n",
       " 'levne',\n",
       " 'den',\n",
       " 'blot',\n",
       " 'mistanke',\n",
       " 'om',\n",
       " 'forurening',\n",
       " 'udgøre',\n",
       " 'den',\n",
       " 'tilstrækkelig',\n",
       " 'retfærdiggørelse',\n",
       " 'for',\n",
       " 'ny',\n",
       " 'felttog',\n",
       " 'mod',\n",
       " 'næringsliv',\n",
       " 'men',\n",
       " 'sådan',\n",
       " 'kunne',\n",
       " 'man',\n",
       " 'jo',\n",
       " 'også',\n",
       " 'indrette',\n",
       " 'indkomstskat',\n",
       " ',',\n",
       " 'hvis',\n",
       " 'man',\n",
       " 'ville',\n",
       " 'denne',\n",
       " 'urimelighed',\n",
       " 'kunne',\n",
       " 'få',\n",
       " 'ungarer',\n",
       " 'til']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = []\n",
    "for sentence in sentences:\n",
    "    all_tokens.extend(sentence)\n",
    "    \n",
    "all_tokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c677af4-ca97-4574-b778-f4512155a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique lemmatized words: 493668\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique lemmatized words: {}\".format(len(set(all_tokens))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49673181-5075-4ae9-ad4d-6e97db8c53f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33983300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7cb416-8a08-40ad-ad93-4ef5c794e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_dic = {\"token\" : all_tokens}\n",
    "df = pd.DataFrame(df_dic)\n",
    "value_count = df[\"token\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca76ab2-8247-4281-9c3c-56f754ff492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ",       2117740\n",
       "og      1000890\n",
       "være     920798\n",
       "i        918440\n",
       "en       774947\n",
       "Name: token, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_count[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77ba4e5-2ceb-47d3-8ec3-72aa1327c9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32940014"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_count[:50000].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac10393-1a0d-44dc-85ba-ae01a89ca642",
   "metadata": {},
   "source": [
    "I want to figure out how many of the most frequent words I need to include in a list in order to cover 90 % of all words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e673066-fc7a-440b-8870-7f5a0ec487b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30584970.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain = value_count.sum() * 0.9 # what is 90 % of all words?\n",
    "explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "071d06fd-9ddf-4b16-9ac1-ad35edf466f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of the most frequent unique words do I need to cover 90 % of all words?\n",
    "def get_idx(percentage):\n",
    "    \"\"\"percentage (float) : What percentage of word occurences should the ith word in value_count account for? Between 0 and 1\"\"\"\n",
    "    explain = value_count.sum() * percentage # what is 90 % of all words?\n",
    "    cont = True\n",
    "    total = 0\n",
    "    for i, num in enumerate(value_count):\n",
    "        total += num\n",
    "        if total >= explain:\n",
    "            print(\"Index of last word to include in value_count: {}\".format(i))\n",
    "            return i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fae4051f-02bb-4d36-954b-62efc809daad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of last word to include in value_count: 7659\n",
      "30585149\n"
     ]
    }
   ],
   "source": [
    "i = get_idx(0.9)\n",
    "print(value_count[:i+1].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83cace97-58a2-4dac-bfdf-98181de73eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_accounted_for(num_unique_words):\n",
    "    pct = value_count[:num_unique_words+1].sum() / value_count.sum() * 100\n",
    "    print(\"{} unique words account for {} % of all words in korpus\".format(num_unique_words, pct))   \n",
    "    return pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f29497b2-10c0-454c-bb90-85694890bc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 unique words account for 90.2366544744036 % of all words in korpus\n"
     ]
    }
   ],
   "source": [
    "percentage_accounted_for(8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf36e861-c2c7-47f7-a8d8-77df3cf62aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 unique words account for 96.93004799416184 % of all words in korpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.93004799416184"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_accounted_for(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5792acf4-ae73-4f2d-84e7-9989caa4f750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66889611-34eb-412a-bf61-51908ae59183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dyerberg                 1\n",
       "forvaltningsdistrikts    1\n",
       "Shysss                   1\n",
       "342500                   1\n",
       "894000                   1\n",
       "                        ..\n",
       "fornuftslov              1\n",
       "Hvalfangskommision       1\n",
       "fangststoppe             1\n",
       "nyindspille              1\n",
       "tvangsmæssighed          1\n",
       "Name: token, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_count[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd9ed8ea-f0b9-4e8b-a067-d1b5fcc82dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221038"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(value_count[value_count > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1e1b4-c948-497e-9476-f29b7eb8d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = value_count[value_count > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "027f1390-1ce6-45d0-8dbf-f4a31b0a799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 unique words account for 91.3711617176672 % of all words in korpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.3711617176672"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_accounted_for(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c7bc97ab-6d8d-40be-89d9-bd7810b9de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 unique words account for 74.16523115765685 % of all words in korpus\n",
      "pct_explained: 74.16523115765685\n",
      "Adding the next 1000 words added a gain of 0.0\n",
      "2000 unique words account for 80.50416822380404 % of all words in korpus\n",
      "pct_explained: 80.50416822380404\n",
      "Adding the next 1000 words added a gain of 6.338937066147196\n",
      "3000 unique words account for 83.80597528786198 % of all words in korpus\n",
      "pct_explained: 83.80597528786198\n",
      "Adding the next 1000 words added a gain of 3.3018070640579396\n",
      "4000 unique words account for 85.93485918083293 % of all words in korpus\n",
      "pct_explained: 85.93485918083293\n",
      "Adding the next 1000 words added a gain of 2.128883892970947\n",
      "5000 unique words account for 87.45002398236781 % of all words in korpus\n",
      "pct_explained: 87.45002398236781\n",
      "Adding the next 1000 words added a gain of 1.5151648015348798\n"
     ]
    }
   ],
   "source": [
    "percentages = []\n",
    "pct_gain = []\n",
    "num_words = []\n",
    "for n in range(1000, len(value_count), 1000):\n",
    "    num_words.append(n)\n",
    "    pct_explained = percentage_accounted_for(n)\n",
    "    print(\"pct_explained: {}\".format(pct_explained))\n",
    "    percentages.append(pct_explained)\n",
    "    if n == 1000:\n",
    "        gain = pct_explained - percentages[-1]\n",
    "    else:\n",
    "        gain = pct_explained - percentages[-2]\n",
    "    print(\"Adding the next 1000 words added a gain of {}\".format(gain))\n",
    "    pct_gain.append(gain)\n",
    "    if n == 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d6298-7cb4-4497-b373-5c6cafcecb91",
   "metadata": {},
   "source": [
    "Save list with 50k most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b1f44ae-c255-4330-a385-4ce365cc0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = value_count[:50001].index # 50,000 most frequent\n",
    "most_frequent_words = most_frequent_words[1:] # removing first \"word\" which is a comma\n",
    "most_frequent_words[0]\n",
    "import pickle\n",
    "pickle.dump(list(most_frequent_words), open('most_frequent_words_50k.pkl', 'wb'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97512c08-a110-47a1-a275-dacfe9283cac",
   "metadata": {},
   "source": [
    "Save list with 8k most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1da97e46-f96c-4620-b1df-914cc177b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = value_count[:8001].index # 50,000 most frequent\n",
    "most_frequent_words = most_frequent_words[1:] # removing first \"word\" which is a comma\n",
    "most_frequent_words[0]\n",
    "import pickle\n",
    "pickle.dump(list(most_frequent_words), open('most_frequent_words_8k.pkl', 'wb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9acc4de1-02a6-480f-b4dd-0488881bc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = value_count[:100001].index # 50,000 most frequent\n",
    "most_frequent_words = most_frequent_words[1:] # removing first \"word\" which is a comma\n",
    "most_frequent_words[0]\n",
    "import pickle\n",
    "pickle.dump(list(most_frequent_words), open('most_frequent_words_100k.pkl', 'wb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3429f9da-3be9-4687-833e-5688ac53f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = value_count[:200001].index # 50,000 most frequent\n",
    "most_frequent_words = most_frequent_words[1:] # removing first \"word\" which is a comma\n",
    "most_frequent_words[0]\n",
    "import pickle\n",
    "pickle.dump(list(most_frequent_words), open('most_frequent_words_200k.pkl', 'wb'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88d17c8a-97af-4eea-ac3f-d0c421f87177",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"most_frequent_words_8k.pkl\", \"rb\") as fp: \n",
    "    test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0df8b8f1-4f30-449b-addc-c9a68880d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "print(len(most_frequent_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb99eadb-99f9-4372-b008-c6e6d624689e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['og', 'være', 'i', 'en', 'den', 'at', 'til', 'det', 'af', 'på']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731c293-d3b9-48a1-b0d7-ee19bc905516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
